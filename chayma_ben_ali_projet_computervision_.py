# -*- coding: utf-8 -*-
"""chayma_ben_ali_projet_computervision_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zykK0UeJo8Eca0XgMud61wrg4MvR7gsi
"""

!7z x "archive.zip"

import os
import random
import shutil

dataset_root = '/content/animals'  # Path to your main dataset folder
train_ratio = 0.8  # Percentage of data for training (80%)
test_ratio = 0.2  # Percentage of data for testing (20%)

os.makedirs(os.path.join(dataset_root, 'train', 'cat'), exist_ok=True)
os.makedirs(os.path.join(dataset_root, 'train', 'dog'), exist_ok=True)
os.makedirs(os.path.join(dataset_root, 'test', 'cat'), exist_ok=True)
os.makedirs(os.path.join(dataset_root, 'test', 'dog'), exist_ok=True)

for animal in ['cat', 'dog']:
    source_dir = os.path.join(dataset_root, animal)
    files = os.listdir(source_dir)
    random.shuffle(files)  # Shuffle for randomness
    train_split_index = int(len(files) * train_ratio)
    train_files = files[:train_split_index]
    test_files = files[train_split_index:]

    for file in train_files:
        shutil.move(os.path.join(source_dir, file), os.path.join(dataset_root, 'train', animal, file))
    for file in test_files:
        shutil.move(os.path.join(source_dir, file), os.path.join(dataset_root, 'test', animal, file))

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

# Paramètres
IMG_SIZE = (128, 128)
DATASET_DIR = 'train'
CATEGORY = 'cat'  # or 'dog', if you want to switch
MASKS_DIR = 'masks'

# Création dossier de masques
os.makedirs(MASKS_DIR, exist_ok=True)

# Récupération aléatoire d'une image depuis le dataset
category_path = os.path.join(DATASET_DIR, CATEGORY)
image_files = [f for f in os.listdir(category_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
assert len(image_files) > 0, "Aucune image trouvée dans le dossier."
selected_image = random.choice(image_files)
img_path = os.path.join(category_path, selected_image)

# Lecture et prétraitement
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img_rgb, IMG_SIZE)
img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)

# 1. Seuillage d'Otsu + morphologie
_, mask_otsu = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
kernel = np.ones((5, 5), np.uint8)
mask_otsu_clean = cv2.morphologyEx(mask_otsu, cv2.MORPH_OPEN, kernel)
mask_otsu_clean = cv2.morphologyEx(mask_otsu_clean, cv2.MORPH_CLOSE, kernel)
cv2.imwrite(os.path.join(MASKS_DIR, 'mask_otsu.png'), mask_otsu_clean)

# 2. Détection de contours (Canny)
mask_canny = cv2.Canny(img_gray, 100, 200)
cv2.imwrite(os.path.join(MASKS_DIR, 'mask_canny.png'), mask_canny)

# 3. Segmentation par couleur (K-Means)
Z = img_resized.reshape((-1, 3))
Z = np.float32(Z)
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
K = 2
_, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
labels = labels.flatten()
mask_kmeans = (labels == labels[0]).astype(np.uint8) * 255  # Fond supposé comme cluster dominant
mask_kmeans = mask_kmeans.reshape(IMG_SIZE)
cv2.imwrite(os.path.join(MASKS_DIR, 'mask_kmeans.png'), mask_kmeans)

# Affichage comparatif
fig, axs = plt.subplots(1, 4, figsize=(20, 5))
axs[0].imshow(img_resized)
axs[0].set_title('Image originale')
axs[1].imshow(mask_otsu_clean, cmap='gray')
axs[1].set_title("Otsu + Morphologie")
axs[2].imshow(mask_canny, cmap='gray')
axs[2].set_title("Contours (Canny)")
axs[3].imshow(mask_kmeans, cmap='gray')
axs[3].set_title("K-Means Couleur")
for ax in axs:
    ax.axis('off')
plt.suptitle(f'Comparaison de segmentation – image: {selected_image}')
plt.tight_layout()
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

# Paramètres
IMG_SIZE = (128, 128)
DATASET_DIR = 'train'
CATEGORY = 'cat'  # change to 'dog' etc. if needed

# Sélection aléatoire d'une image
category_path = os.path.join(DATASET_DIR, CATEGORY)
image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
assert len(image_files) > 0, f"Aucune image trouvée dans {category_path}"
selected_image = random.choice(image_files)
img_path = os.path.join(category_path, selected_image)

# Lecture et conversion RGB
img = cv2.imread(img_path)
if img is None:
    raise FileNotFoundError(f"Image non trouvée : {img_path}")
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Redimensionnement
img_resized = cv2.resize(img_rgb, IMG_SIZE)

# Normalisation
img_norm = img_resized / 255.0
img_norm_uint8 = (img_norm * 255).astype(np.uint8)

# Filtre bilatéral (sur image originale)
img_bilateral = cv2.bilateralFilter(img_rgb, 9, 75, 75)

# Niveaux de gris (sur image filtrée)
img_gray = cv2.cvtColor(img_bilateral, cv2.COLOR_RGB2GRAY)

# Affichage
fig, axs = plt.subplots(1, 5, figsize=(25, 5))
axs[0].imshow(img_rgb)
axs[0].set_title('Originale')
axs[1].imshow(img_resized)
axs[1].set_title('Redimensionnée')
axs[2].imshow(img_norm)
axs[2].set_title('Normalisée')
axs[3].imshow(img_bilateral)
axs[3].set_title('Filtre bilatéral')
axs[4].imshow(img_gray, cmap='gray')
axs[4].set_title('Niveaux de gris')

for ax in axs:
    ax.axis('off')
plt.suptitle(f'Prétraitements sur : {selected_image}')
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import random # Pour choisir des images aléatoires si on veut

# --- Configuration ---
# Chemin vers le dossier principal contenant les sous-dossiers 'cats' et 'dogs'
# !! IMPORTANT !! Modifie ce chemin si ton dossier 'training_set' n'est pas au même endroit que le script
# Par exemple: DATA_BASE_DIR = 'C:/Users/TonNom/Downloads/chemin/vers/le/dataset'
# Ou laisse comme ça si 'training_set' est dans le même dossier que ce script.
DATA_BASE_DIR = './'  # Le '.' signifie le dossier courant
TRAIN_FOLDER = 'train' # Nom du dossier contenant les images d'entraînement

# Classes que nous voulons traiter
CLASSES = ['cat', 'dog']

# Paramètres pour les images
IMG_WIDTH = 128  # Largeur souhaitée pour les images redimensionnées
IMG_HEIGHT = 128 # Hauteur souhaitée
IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)

# Combien d'exemples montrer pour chaque classe
N_SAMPLES_TO_SHOW = 2

# --- Fonctions Utilitaires ---

def charger_chemins_images(base_dir, classe, n_samples):
    """
    Charge les chemins complets d'un nombre donné d'images pour une classe spécifique.
    Retourne une liste de chemins d'images.
    Gère le cas où le dossier n'existe pas ou s'il n'y a pas assez d'images.
    """
    # Construit le chemin complet vers le dossier de la classe
    class_dir = os.path.join(base_dir, TRAIN_FOLDER, classe)

    # Vérifie si le dossier existe
    if not os.path.isdir(class_dir):
        print(f"ERREUR : Le dossier '{class_dir}' est introuvable.")
        return [] # Retourne une liste vide si le dossier n'existe pas

    # Liste tous les fichiers dans le dossier
    try:
        all_files = [f for f in os.listdir(class_dir)
                     if os.path.isfile(os.path.join(class_dir, f)) and
                        f.lower().endswith(('.jpg', '.jpeg', '.png'))] # Accepte plusieurs extensions
    except OSError as e:
        print(f"ERREUR : Impossible de lire le dossier '{class_dir}'. Détails : {e}")
        return []

    # Vérifie s'il y a des images
    if not all_files:
        print(f"AVERTISSEMENT : Aucun fichier image (.jpg, .jpeg, .png) trouvé dans '{class_dir}'.")
        return []

    # Sélectionne N images (aléatoirement ou les premières)
    # Ici, on prend les premières pour la reproductibilité, mais random.sample est une option
    # selected_files = random.sample(all_files, min(n_samples, len(all_files)))
    selected_files = all_files[:min(n_samples, len(all_files))] # Prend les N premières ou moins si pas assez

    # Crée les chemins complets
    image_paths = [os.path.join(class_dir, f) for f in selected_files]

    return image_paths

def appliquer_pretraitement(image_path, target_size):
    """
    Charge une image et applique une série d'étapes de prétraitement.
    Retourne un dictionnaire contenant l'image à chaque étape.
    """
    try:
        # 1. Lecture de l'image depuis le fichier
        # cv2.imread charge l'image en format BGR (Bleu, Vert, Rouge) par défaut
        img_bgr = cv2.imread(image_path)
        if img_bgr is None:
            print(f"AVERTISSEMENT : Impossible de charger l'image : {image_path}")
            return None

        # 2. Conversion BGR -> RGB
        # Matplotlib s'attend à du RGB pour un affichage correct des couleurs
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        # 3. Redimensionnement
        # On met toutes les images à la même taille pour le modèle d'IA
        img_resized = cv2.resize(img_rgb, target_size, interpolation=cv2.INTER_AREA)

        # 4. Normalisation des pixels
        # On ramène les valeurs des pixels de [0, 255] à [0.0, 1.0]
        # Utile pour l'entraînement des réseaux de neurones
        img_norm = img_resized / 255.0

        # 5. Filtrage (Optionnel, ici Flou Gaussien)
        # Peut aider à réduire le bruit dans l'image
        # (5, 5) est la taille du noyau de flou, 0 est l'écart-type (calculé automatiquement)
        img_filtered = cv2.GaussianBlur(img_norm, (5, 5), 0)

        # 6. Conversion en niveaux de gris
        # Réduit l'information (perd la couleur) mais peut être suffisant pour certaines tâches
        # Il faut repasser en format 8-bit (0-255) avant la conversion
        img_gray = cv2.cvtColor((img_filtered * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)

        # 7. Amélioration du contraste (Égalisation d'Histogramme)
        # Utile surtout pour les images en niveaux de gris, pour mieux voir les détails
        # Répartit l'intensité des pixels sur toute la plage possible
        img_eq = cv2.equalizeHist(img_gray)

        # Stocke toutes les étapes dans un dictionnaire pour une utilisation facile
        etapes_pretraitement = {
            'Original': img_rgb,
            'Redimensionnée': img_resized,
            'Normalisée': img_norm,
            'Filtrée (Flou)': img_filtered,
            'Niveaux de gris': img_gray,
            'Contraste amélioré': img_eq
        }
        return etapes_pretraitement

    except Exception as e:
        print(f"ERREUR lors du prétraitement de l'image {image_path}: {e}")
        return None

def visualiser_etapes(etapes_dict, titre_base):
    """
    Affiche les différentes étapes du prétraitement stockées dans le dictionnaire.
    """
    if etapes_dict is None:
        return # Ne rien faire si le prétraitement a échoué

    n_etapes = len(etapes_dict)
    fig, axs = plt.subplots(1, n_etapes, figsize=(n_etapes * 3.5, 4)) # Ajuste la taille

    # Parcourt le dictionnaire et affiche chaque image
    for i, (nom_etape, image) in enumerate(etapes_dict.items()):
        ax = axs[i]
        # Utilise 'cmap=gray' pour les images en niveaux de gris
        if image.ndim == 2:
            ax.imshow(image, cmap='gray')
        else:
            ax.imshow(image)
        ax.set_title(nom_etape)
        ax.axis('off') # Cache les axes (x, y)

    plt.suptitle(titre_base, fontsize=14)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajuste pour laisser de la place au suptitle
    plt.show()

# --- Script Principal ---
if __name__ == "__main__":
    print("--- Début du script de visualisation du prétraitement ---")
    print(f"Recherche des images dans : {os.path.abspath(os.path.join(DATA_BASE_DIR, TRAIN_FOLDER))}")
    print(f"Taille cible des images : {IMG_SIZE}")
    print(f"Nombre d'exemples par classe : {N_SAMPLES_TO_SHOW}\n")

    # Boucle sur chaque classe ('cat', 'dog')
    for classe_animal in CLASSES:
        print(f"--- Traitement de la classe : {classe_animal.capitalize()} ---")

        # Récupère les chemins des images pour cette classe
        chemins_images = charger_chemins_images(DATA_BASE_DIR, classe_animal, N_SAMPLES_TO_SHOW)

        # Si on a trouvé des images, on les traite et les affiche
        if chemins_images:
            print(f"Affichage de {len(chemins_images)} exemple(s)...")
            for i, chemin in enumerate(chemins_images):
                print(f"  Prétraitement de : {os.path.basename(chemin)}")
                # Applique toutes les étapes de prétraitement
                etapes = appliquer_pretraitement(chemin, IMG_SIZE)

                # Si le prétraitement a réussi, affiche les résultats
                if etapes:
                    titre = f"{classe_animal.capitalize()} - Exemple {i+1}"
                    visualiser_etapes(etapes, titre)
        else:
            print(f"Aucune image à afficher pour la classe {classe_animal}.")
        print("-" * (len(classe_animal) + 28) + "\n") # Séparateur

    print("--- Fin du script ---")

# %% YOLO Segmentation using YOLOv8
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import time

# First we need to install the ultralytics package which has YOLOv8
print("Installing ultralytics package for YOLOv8...")
!pip install ultralytics

# Import after installation
from ultralytics import YOLO

# %% Configuration
# Use the same cat image as before
IMAGE_FILENAME = '00000-4122619873.png'
IMAGE_CLASS_DIR = 'cat'
IMAGE_SET_DIR = 'train'
IMAGE_PATH = os.path.join(IMAGE_SET_DIR, IMAGE_CLASS_DIR, IMAGE_FILENAME)

print(f"Configuring YOLOv8 segmentation for image: {IMAGE_PATH}")

# %% Load the YOLOv8 segmentation model
print("Loading YOLOv8 segmentation model...")
try:
    # Load the segmentation model (will download if not present)
    # Using the 'segment' variant specifically trained for segmentation
    model = YOLO('yolov8n-seg.pt') # 'n' is the smallest/fastest model
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")
    raise SystemExit("Model loading failed.")

# %% Load the image and run segmentation
print(f"Loading image: {IMAGE_PATH}...")
try:
    if not os.path.exists(IMAGE_PATH):
        raise FileNotFoundError(f"Image file not found at: {os.path.abspath(IMAGE_PATH)}")

    # Read the image and convert for display
    img = cv2.imread(IMAGE_PATH)
    if img is None:
        raise IOError(f"Could not read image file: {IMAGE_PATH}")

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    height, width = img.shape[:2]
    print(f"Image loaded successfully (Height: {height}, Width: {width}).")

    # Run YOLOv8 segmentation
    print("Running segmentation inference...")
    start_time = time.time()
    results = model.predict(source=IMAGE_PATH, conf=0.25, save=False, verbose=False)
    end_time = time.time()
    print(f"Inference completed in {end_time - start_time:.2f} seconds.")

    # Get the result (first image result)
    result = results[0]

    # %% Visualize the results
    print("Processing and visualizing segmentation results...")

    # Create a figure with 1 row, 2 columns
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))

    # Plot the original image in the first subplot
    axes[0].imshow(img_rgb)
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    # Extract masks, boxes, and labels from results
    masks = result.masks.data if result.masks is not None else None
    boxes = result.boxes.data if result.boxes is not None else None
    cls = result.boxes.cls.cpu().numpy() if result.boxes is not None else []
    conf = result.boxes.conf.cpu().numpy() if result.boxes is not None else []

    # Get the class names
    class_names = result.names

    # Create a copy of the original image to draw segmentation on
    seg_img = img_rgb.copy()

    if masks is not None and len(masks) > 0:
        print(f"Found {len(masks)} segmentation masks")

        # Create random colors for each class
        np.random.seed(42)  # For reproducibility
        colors = np.random.randint(0, 255, size=(len(class_names), 3), dtype='uint8')

        # Create a blank mask image
        overlay = np.zeros_like(img_rgb)

        # For each detected object
        for i, (mask, box) in enumerate(zip(masks, boxes)):
            # Convert mask from tensor to numpy
            mask = mask.cpu().numpy()

            # Get class ID and name
            class_id = int(cls[i])
            class_name = class_names[class_id]
            confidence = conf[i]

            # Get color for this class
            color = colors[class_id]

            # Convert mask to binary image
            binary_mask = mask.astype(np.uint8)

            # Resize mask to image size if needed
            if binary_mask.shape != (height, width):
                binary_mask = cv2.resize(binary_mask, (width, height))

            # Apply the mask color to overlay
            for c in range(3):
                overlay[:, :, c] = np.where(binary_mask == 1,
                                           color[c],
                                           overlay[:, :, c])

            # Get box coordinates
            x1, y1, x2, y2 = box[:4].cpu().numpy().astype(int)

            # Draw bounding box
            cv2.rectangle(seg_img, (x1, y1), (x2, y2), color.tolist(), 2)

            # Create label text
            label = f"{class_name}: {confidence:.2f}"

            # Draw filled rectangle for text background
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(seg_img,
                         (x1, y1 - text_height - baseline),
                         (x1 + text_width, y1),
                         color.tolist(), -1)

            # Draw text label
            cv2.putText(seg_img, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # Blend original image with overlay (semi-transparent masks)
        alpha = 0.5  # transparency factor
        cv2.addWeighted(overlay, alpha, seg_img, 1 - alpha, 0, seg_img)

        # Plot the segmentation result in the second subplot
        axes[1].imshow(seg_img)
        axes[1].set_title('YOLOv8 Segmentation')
        axes[1].axis('off')

    else:
        print("No segmentation masks found!")
        axes[1].imshow(img_rgb)
        axes[1].set_title('No Segmentation Masks Found')
        axes[1].axis('off')

    plt.tight_layout()
    plt.show()

except FileNotFoundError as fnf_error:
    print(f"Error: {fnf_error}")
    print(f"Please ensure the image exists at: {os.path.abspath(IMAGE_PATH)}")
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    import traceback
    print(traceback.format_exc())

# %% Generate Binary Masks using YOLOv8
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import time
from tqdm.notebook import tqdm  # For progress bars

# Install ultralytics if not already installed
try:
    from ultralytics import YOLO
except ImportError:
    print("Installing ultralytics package for YOLOv8...")
    !pip install ultralytics
    from ultralytics import YOLO

# %% Configuration
# Define paths
DATA_DIR = '.'  # Root directory
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
OUTPUT_DIR = os.path.join(DATA_DIR, 'masks')  # Output directory for masks

# Create output directory if it doesn't exist
os.makedirs(OUTPUT_DIR, exist_ok=True)

# %% Load the YOLOv8 segmentation model
print("Loading YOLOv8 segmentation model...")
try:
    # Load the segmentation model
    model = YOLO('yolov8n-seg.pt')  # Using the nano model for speed
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")
    raise SystemExit("Model loading failed.")

# Function to process a single image and save its mask
def process_image(image_path, output_dir):
    # Get relative path components for organizing output
    rel_path = os.path.relpath(image_path, DATA_DIR)

    # Parse components (dataset/class/filename)
    path_parts = os.path.normpath(rel_path).split(os.sep)
    if len(path_parts) >= 3:
        dataset_type = path_parts[0]  # 'train' or 'test'
        class_name = path_parts[1]    # e.g., 'cat', 'dog'
        file_name = path_parts[2]     # e.g., '00001.png'
    else:
        # If path structure is different, use a fallback approach
        file_name = os.path.basename(image_path)
        class_name = os.path.basename(os.path.dirname(image_path))
        dataset_type = "unknown"

    # Create output class directory if needed
    class_output_dir = os.path.join(output_dir, dataset_type, class_name)
    os.makedirs(class_output_dir, exist_ok=True)

    # Output mask path - same filename in the output directory
    mask_name = os.path.splitext(file_name)[0] + "_mask.png"
    mask_path = os.path.join(class_output_dir, mask_name)

    # Skip if mask already exists
    if os.path.exists(mask_path):
        return None, "already_exists"

    try:
        # Run YOLOv8 segmentation
        results = model.predict(source=image_path, conf=0.25, save=False, verbose=False)
        result = results[0]

        # Get the image dimensions
        img = cv2.imread(image_path)
        if img is None:
            return image_path, "image_read_error"

        height, width = img.shape[:2]

        # Check if masks exist in the results
        if result.masks is None or len(result.masks.data) == 0:
            # No masks found - create a blank mask
            binary_mask = np.zeros((height, width), dtype=np.uint8)
            status = "no_masks_found"
        else:
            # Get the first mask (assuming main subject is the first detected object)
            # Or we could combine all masks if there are multiple objects
            masks = result.masks.data
            cls = result.boxes.cls.cpu().numpy() if result.boxes is not None else []

            # Find cat or dog class IDs (0 and 16 in COCO dataset)
            # COCO class IDs: cat=15, dog=16 (0-indexed in YOLOv8)
            target_classes = [15, 16]  # cat and dog IDs in COCO

            # Initialize empty mask
            binary_mask = np.zeros((height, width), dtype=np.uint8)

            # First check if any target animals were detected
            target_indices = [i for i, c in enumerate(cls) if int(c) in target_classes]

            if target_indices:
                # Only use masks for target animal classes
                for idx in target_indices:
                    mask = masks[idx].cpu().numpy()

                    # Resize mask to image size if needed
                    if mask.shape != (height, width):
                        mask = cv2.resize(mask.astype(np.uint8), (width, height))

                    # Combine with existing mask (logical OR)
                    binary_mask = np.logical_or(binary_mask, mask).astype(np.uint8) * 255
                status = "target_animal_detected"
            else:
                # If no target animals, use the first mask (if any)
                if len(masks) > 0:
                    mask = masks[0].cpu().numpy()

                    # Resize mask to image size if needed
                    if mask.shape != (height, width):
                        mask = cv2.resize(mask.astype(np.uint8), (width, height))

                    binary_mask = mask.astype(np.uint8) * 255
                    status = "used_first_mask"
                else:
                    status = "no_masks_found"

        # Save the binary mask as PNG
        cv2.imwrite(mask_path, binary_mask)
        return mask_path, status

    except Exception as e:
        return image_path, f"error: {str(e)}"

# %% Process all image files
def find_image_files(directory):
    image_paths = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    return image_paths

# Find all images in train and test directories
print("Finding image files...")
train_images = find_image_files(TRAIN_DIR)
test_images = find_image_files(TEST_DIR)
all_images = train_images + test_images
print(f"Found {len(train_images)} training images and {len(test_images)} test images.")

# Process all images and generate masks
print("Generating binary masks...")
results = {}

for img_path in tqdm(all_images, desc="Processing images"):
    output_path, status = process_image(img_path, OUTPUT_DIR)
    if output_path:
        results[img_path] = status

# %% Print summary
print("\nMask Generation Complete!")
print(f"Total images processed: {len(all_images)}")

# Count statuses
status_counts = {}
for status in results.values():
    status_counts[status] = status_counts.get(status, 0) + 1

print("\nStatus Summary:")
for status, count in status_counts.items():
    print(f"  {status}: {count}")

print(f"\nMasks saved to: {os.path.abspath(OUTPUT_DIR)}")

# Optional: Display a few examples
num_examples = min(3, len(all_images))
if num_examples > 0:
    print(f"\nShowing {num_examples} examples:")

    fig, axes = plt.subplots(num_examples, 2, figsize=(12, 4*num_examples))
    if num_examples == 1:
        axes = axes.reshape(1, 2)

    for i in range(num_examples):
        img_path = all_images[i]

        # Get corresponding mask path
        rel_path = os.path.relpath(img_path, DATA_DIR)
        path_parts = os.path.normpath(rel_path).split(os.sep)
        if len(path_parts) >= 3:
            dataset_type = path_parts[0]
            class_name = path_parts[1]
            file_name = path_parts[2]
            mask_name = os.path.splitext(file_name)[0] + "_mask.png"
            mask_path = os.path.join(OUTPUT_DIR, dataset_type, class_name, mask_name)
        else:
            # Fallback if path structure is different
            continue

        # Display image and mask
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        if os.path.exists(mask_path):
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            axes[i, 0].imshow(img_rgb)
            axes[i, 0].set_title(f"Original: {os.path.basename(img_path)}")
            axes[i, 0].axis('off')

            axes[i, 1].imshow(mask, cmap='gray')
            axes[i, 1].set_title(f"Mask: {os.path.basename(mask_path)}")
            axes[i, 1].axis('off')

    plt.tight_layout()
    plt.show()

# %% Feature Extraction - Training Files Only
import cv2
import numpy as np
from skimage.feature import graycomatrix, graycoprops
import os
from tqdm.notebook import tqdm
import pandas as pd

# Define paths
DATA_DIR = '.'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')  # Only using training dir
MASKS_DIR = os.path.join(DATA_DIR, 'masks')

# Output CSV path
OUTPUT_CSV = os.path.join(DATA_DIR, 'train_features.csv')  # Changed name to indicate train-only

# Extract features from an image and its mask
def extract_features(image_path, mask_path, class_label):
    try:
        # Load image and mask
        img = cv2.imread(image_path)
        binary_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if img is None or binary_mask is None:
            return None

        # Ensure mask is binary
        _, binary_mask = cv2.threshold(binary_mask, 127, 255, cv2.THRESH_BINARY)

        # Convert to grayscale for photometric features
        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Find contours
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        feature_vectors = []

        for cnt in contours:
            if cv2.contourArea(cnt) < 50:  # Skip small noise
                continue

            # === Geometric Features ===
            area = cv2.contourArea(cnt)
            perimeter = cv2.arcLength(cnt, True)
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = float(w) / h if h != 0 else 0
            circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0

            # === Photometric Features ===
            # Create mask for this contour
            mask = np.zeros_like(gray_img)
            cv2.drawContours(mask, [cnt], 0, 255, -1)

            # Get ROI
            mask_roi = mask[y:y+h, x:x+w]
            img_roi = gray_img[y:y+h, x:x+w]

            if mask_roi.size == 0 or img_roi.size == 0:
                continue

            # Calculate mean and std intensity
            mean_intensity = np.mean(img_roi[mask_roi == 255]) if np.any(mask_roi == 255) else 0
            std_intensity = np.std(img_roi[mask_roi == 255]) if np.any(mask_roi == 255) else 0

            # GLCM features for texture
            energy = homogeneity = entropy = 0
            if img_roi.shape[0] > 1 and img_roi.shape[1] > 1 and np.any(mask_roi == 255):
                try:
                    glcm = graycomatrix(img_roi, [1], [0], levels=256, symmetric=True, normed=True)
                    energy = graycoprops(glcm, 'energy')[0, 0]
                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
                    entropy = -np.sum(glcm * np.log2(glcm + 1e-10))
                except:
                    pass

            # Feature vector with filename and class
            feature_vector = [
                os.path.basename(image_path),
                class_label,
                area,
                perimeter,
                aspect_ratio,
                circularity,
                mean_intensity,
                std_intensity,
                energy,
                homogeneity,
                entropy
            ]

            feature_vectors.append(feature_vector)

        # If no contours were found, add a row with just the filename, class, and zeros
        if len(feature_vectors) == 0:
            feature_vectors.append([
                os.path.basename(image_path),
                class_label,
                0, 0, 0, 0, 0, 0, 0, 0, 0  # All features as zero
            ])

        return feature_vectors

    except Exception as e:
        print(f"Error processing {image_path}: {str(e)}")
        return None

# Find mask for a given image
def find_mask_path(image_path):
    rel_path = os.path.relpath(image_path, DATA_DIR)
    path_parts = os.path.normpath(rel_path).split(os.sep)

    if len(path_parts) >= 3:
        dataset_type = path_parts[0]  # 'train'
        class_name = path_parts[1]    # 'cat' or 'dog'
        file_name = path_parts[2]     # image filename

        mask_name = os.path.splitext(file_name)[0] + "_mask.png"
        mask_path = os.path.join(MASKS_DIR, dataset_type, class_name, mask_name)

        if os.path.exists(mask_path):
            return mask_path

    return None

# Get ONLY training images (removed test image collection)
train_images = []
train_labels = []

# Train images only
for class_name in ['cat', 'dog']:
    class_dir = os.path.join(TRAIN_DIR, class_name)
    if os.path.exists(class_dir):
        for file in os.listdir(class_dir):
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                train_images.append(os.path.join(class_dir, file))
                train_labels.append(class_name)

print(f"Found {len(train_images)} training images")

# Process only training images
all_features = []
for img_path, label in tqdm(zip(train_images, train_labels), total=len(train_images)):
    mask_path = find_mask_path(img_path)
    if mask_path:
        features = extract_features(img_path, mask_path, label)
        if features:
            all_features.extend(features)

# Create DataFrame and save to CSV
columns = [
    'filename', 'class',
    'area', 'perimeter', 'aspect_ratio', 'circularity',
    'mean_intensity', 'std_intensity',
    'energy', 'homogeneity', 'entropy'
]

df = pd.DataFrame(all_features, columns=columns)
df.to_csv(OUTPUT_CSV, index=False)

print(f"Feature vectors saved to {OUTPUT_CSV}")
print(f"Total vectors: {len(df)}")

# %% Feature Extraction - testing Files Only
import cv2
import numpy as np
from skimage.feature import graycomatrix, graycoprops
import os
from tqdm.notebook import tqdm
import pandas as pd

# Define paths
DATA_DIR = '.'
test_DIR = os.path.join(DATA_DIR, 'test')  # Only using testing dir
MASKS_DIR = os.path.join(DATA_DIR, 'masks')

# Output CSV path
OUTPUT_CSV = os.path.join(DATA_DIR, 'test_features.csv')  # Changed name to indicate test-only

# Extract features from an image and its mask
def extract_features(image_path, mask_path, class_label):
    try:
        # Load image and mask
        img = cv2.imread(image_path)
        binary_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if img is None or binary_mask is None:
            return None

        # Ensure mask is binary
        _, binary_mask = cv2.threshold(binary_mask, 127, 255, cv2.THRESH_BINARY)

        # Convert to grayscale for photometric features
        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Find contours
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        feature_vectors = []

        for cnt in contours:
            if cv2.contourArea(cnt) < 50:  # Skip small noise
                continue

            # === Geometric Features ===
            area = cv2.contourArea(cnt)
            perimeter = cv2.arcLength(cnt, True)
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = float(w) / h if h != 0 else 0
            circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0

            # === Photometric Features ===
            # Create mask for this contour
            mask = np.zeros_like(gray_img)
            cv2.drawContours(mask, [cnt], 0, 255, -1)

            # Get ROI
            mask_roi = mask[y:y+h, x:x+w]
            img_roi = gray_img[y:y+h, x:x+w]

            if mask_roi.size == 0 or img_roi.size == 0:
                continue

            # Calculate mean and std intensity
            mean_intensity = np.mean(img_roi[mask_roi == 255]) if np.any(mask_roi == 255) else 0
            std_intensity = np.std(img_roi[mask_roi == 255]) if np.any(mask_roi == 255) else 0

            # GLCM features for texture
            energy = homogeneity = entropy = 0
            if img_roi.shape[0] > 1 and img_roi.shape[1] > 1 and np.any(mask_roi == 255):
                try:
                    glcm = graycomatrix(img_roi, [1], [0], levels=256, symmetric=True, normed=True)
                    energy = graycoprops(glcm, 'energy')[0, 0]
                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]
                    entropy = -np.sum(glcm * np.log2(glcm + 1e-10))
                except:
                    pass

            # Feature vector with filename and class
            feature_vector = [
                os.path.basename(image_path),
                class_label,
                area,
                perimeter,
                aspect_ratio,
                circularity,
                mean_intensity,
                std_intensity,
                energy,
                homogeneity,
                entropy
            ]

            feature_vectors.append(feature_vector)

        # If no contours were found, add a row with just the filename, class, and zeros
        if len(feature_vectors) == 0:
            feature_vectors.append([
                os.path.basename(image_path),
                class_label,
                0, 0, 0, 0, 0, 0, 0, 0, 0  # All features as zero
            ])

        return feature_vectors

    except Exception as e:
        print(f"Error processing {image_path}: {str(e)}")
        return None

# Find mask for a given image
def find_mask_path(image_path):
    rel_path = os.path.relpath(image_path, DATA_DIR)
    path_parts = os.path.normpath(rel_path).split(os.sep)

    if len(path_parts) >= 3:
        dataset_type = path_parts[0]  # 'test'
        class_name = path_parts[1]    # 'cat' or 'dog'
        file_name = path_parts[2]     # image filename

        mask_name = os.path.splitext(file_name)[0] + "_mask.png"
        mask_path = os.path.join(MASKS_DIR, dataset_type, class_name, mask_name)

        if os.path.exists(mask_path):
            return mask_path

    return None

# Get ONLY testing images (removed test image collection)
test_images = []
test_labels = []

# test images only
for class_name in ['cat', 'dog']:
    class_dir = os.path.join(test_DIR, class_name)
    if os.path.exists(class_dir):
        for file in os.listdir(class_dir):
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                test_images.append(os.path.join(class_dir, file))
                test_labels.append(class_name)

print(f"Found {len(test_images)} testing images")

# Process only testing images
all_features = []
for img_path, label in tqdm(zip(test_images, test_labels), total=len(test_images)):
    mask_path = find_mask_path(img_path)
    if mask_path:
        features = extract_features(img_path, mask_path, label)
        if features:
            all_features.extend(features)

# Create DataFrame and save to CSV
columns = [
    'filename', 'class',
    'area', 'perimeter', 'aspect_ratio', 'circularity',
    'mean_intensity', 'std_intensity',
    'energy', 'homogeneity', 'entropy'
]

df = pd.DataFrame(all_features, columns=columns)
df.to_csv(OUTPUT_CSV, index=False)

print(f"Feature vectors saved to {OUTPUT_CSV}")
print(f"Total vectors: {len(df)}")

# -*- coding: utf-8 -*-
"""classification_ml.py

Ce script implémente la partie classification Machine Learning du projet
pour la classification Chat/Chien à partir des caractéristiques extraites
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import learning_curve
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc
)

# Import des classifieurs
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# Fonction pour charger et préparer les données
def load_and_prepare_data(train_csv, test_csv):
    """
    Charge les caractéristiques depuis les CSV et prépare les données pour la classification
    """
    # Charger les données
    train_df = pd.read_csv(train_csv)
    test_df = pd.read_csv(test_csv)

    # Vérification du chargement des données
    print(f"Données d'entraînement : {train_df.shape}")
    print(f"Données de test : {test_df.shape}")

    # Séparer les caractéristiques et les étiquettes
    feature_cols = ['area', 'perimeter', 'aspect_ratio', 'circularity',
                    'mean_intensity', 'std_intensity', 'energy', 'homogeneity', 'entropy']

    X_train = train_df[feature_cols].values
    X_test = test_df[feature_cols].values

    # Convertir les classes en valeurs numériques (cat=0, dog=1)
    y_train = (train_df['class'] == 'dog').astype(int)
    y_test = (test_df['class'] == 'dog').astype(int)

    # Normaliser les caractéristiques (important pour SVM et KNN)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, y_train, X_test_scaled, y_test, feature_cols

def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):
    """
    Dessine la courbe d'apprentissage pour un estimateur
    """
    plt.figure(figsize=(10, 6))
    plt.title(title)
    plt.xlabel("Taille de l'ensemble d'entraînement")
    plt.ylabel("Score")

    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='accuracy')

    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)

    plt.grid()
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Train score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Test score")

    plt.legend(loc="best")
    return plt

def evaluate_classifier(clf, X_train, y_train, X_test, y_test, name):
    """
    Évalue un classifieur et affiche les résultats
    """
    # Apprentissage
    print(f"\n--- Évaluation de {name} ---")
    clf.fit(X_train, y_train)

    # Prédictions
    y_pred = clf.predict(X_test)

    # Métriques d'évaluation
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])
    plt.title(f'Matrice de confusion - {name}')
    plt.ylabel('Vraie classe')
    plt.xlabel('Classe prédite')
    plt.tight_layout()
    plt.savefig(f"confusion_matrix_{name.replace(' ', '_').lower()}.png")
    plt.show()

    # Courbe d'apprentissage
    plot_learning_curve(clf, f"Courbe d'apprentissage - {name}", X_train, y_train)
    plt.savefig(f"learning_curve_{name.replace(' ', '_').lower()}.png")
    plt.show()

    # Si le classifieur fournit des probabilités, tracer la courbe ROC
    if hasattr(clf, "predict_proba"):
        try:
            y_proba = clf.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            roc_auc = auc(fpr, tpr)

            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, color='darkorange', lw=2,
                     label=f'Courbe ROC (AUC = {roc_auc:.2f})')
            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('Taux de faux positifs')
            plt.ylabel('Taux de vrais positifs')
            plt.title(f'Courbe ROC - {name}')
            plt.legend(loc="lower right")
            plt.savefig(f"roc_curve_{name.replace(' ', '_').lower()}.png")
            plt.show()
        except:
            print("Impossible de calculer la courbe ROC pour ce classifieur")

    return {
        'name': name,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

def plot_feature_importance(X_train, feature_names, clf, title):
    """
    Affiche l'importance des caractéristiques pour les modèles qui le supportent
    """
    if hasattr(clf, 'feature_importances_'):
        # Obtenir les importances
        importances = clf.feature_importances_
        indices = np.argsort(importances)[::-1]

        plt.figure(figsize=(10, 6))
        plt.title(title)
        plt.bar(range(X_train.shape[1]), importances[indices], align='center')
        plt.xticks(range(X_train.shape[1]), [feature_names[i] for i in indices], rotation=90)
        plt.tight_layout()
        plt.savefig(f"feature_importance_{title.replace(' ', '_').lower()}.png")
        plt.show()

# Programme principal
if __name__ == "__main__":
    # Chemins des fichiers CSV de caractéristiques
    TRAIN_CSV = 'train_features.csv'
    TEST_CSV = 'test_features.csv'

    # Charger et préparer les données
    X_train, y_train, X_test, y_test, feature_names = load_and_prepare_data(TRAIN_CSV, TEST_CSV)

    # Liste des classifieurs à tester
    classifiers = [
        (SVC(kernel='rbf', C=10, gamma='scale', probability=True), 'SVM'),
        (KNeighborsClassifier(n_neighbors=5), 'k-NN'),
        (RandomForestClassifier(n_estimators=100, random_state=42), 'Random Forest'),
        (LogisticRegression(max_iter=1000, random_state=42), 'Régression Logistique')
    ]

    # Évaluer chaque classifieur
    results = []
    for clf, name in classifiers:
        result = evaluate_classifier(clf, X_train, y_train, X_test, y_test, name)
        results.append(result)

        # Afficher l'importance des caractéristiques pour Random Forest
        if name == 'Random Forest':
            plot_feature_importance(X_train, feature_names, clf, "Importance des caractéristiques - Random Forest")

    # Tableau comparatif
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values(by='accuracy', ascending=False)

    print("\n--- Tableau comparatif des modèles ---")
    print(results_df)

    # Visualiser la comparaison des performances
    plt.figure(figsize=(12, 8))
    metrics = ['accuracy', 'precision', 'recall', 'f1']
    results_df_plot = results_df.melt(id_vars=['name'], value_vars=metrics,
                                    var_name='Métrique', value_name='Score')

    sns.barplot(x='name', y='Score', hue='Métrique', data=results_df_plot)
    plt.title('Comparaison des performances des classifieurs')
    plt.xlabel('Modèle')
    plt.ylabel('Score')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig("model_comparison.png")
    plt.show()

# -*- coding: utf-8 -*-
"""feature_analysis.py

Ce script analyse les caractéristiques extraites et visualise leur distribution
pour mieux comprendre leur pouvoir discriminant entre chats et chiens
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.stats import ttest_ind

# Charger les données
def load_data(csv_path):
    """Charge les données de caractéristiques depuis le CSV"""
    df = pd.read_csv(csv_path)
    return df

def visualize_feature_distributions(df, output_dir='.'):
    """Visualise la distribution de chaque caractéristique par classe"""
    features = ['area', 'perimeter', 'aspect_ratio', 'circularity',
                'mean_intensity', 'std_intensity', 'energy', 'homogeneity', 'entropy']

    # Configuration de la figure
    n_features = len(features)
    fig, axes = plt.subplots(n_features, 1, figsize=(12, 4*n_features))

    for i, feature in enumerate(features):
        ax = axes[i]
        sns.boxplot(x='class', y=feature, data=df, ax=ax)
        ax.set_title(f'Distribution de {feature} par classe')

        # Test statistique pour montrer la significativité
        cats = df[df['class'] == 'cat'][feature].dropna()
        dogs = df[df['class'] == 'dog'][feature].dropna()

        if len(cats) > 0 and len(dogs) > 0:
            t_stat, p_val = ttest_ind(cats, dogs, equal_var=False)
            significance = "***" if p_val < 0.001 else "**" if p_val < 0.01 else "*" if p_val < 0.05 else "ns"
            ax.set_title(f'Distribution de {feature} par classe (p={p_val:.4f} {significance})')

    plt.tight_layout()
    plt.savefig(f"{output_dir}/feature_distributions.png")
    plt.show()

def generate_correlation_matrix(df, output_dir='.'):
    """Génère une matrice de corrélation entre les caractéristiques"""
    features = ['area', 'perimeter', 'aspect_ratio', 'circularity',
                'mean_intensity', 'std_intensity', 'energy', 'homogeneity', 'entropy']

    # Créer un DataFrame pour chaque classe
    df_cat = df[df['class'] == 'cat'][features]
    df_dog = df[df['class'] == 'dog'][features]

    # Calculer les matrices de corrélation
    corr_cat = df_cat.corr()
    corr_dog = df_dog.corr()

    # Configuration des figures
    fig, axes = plt.subplots(1, 2, figsize=(20, 8))

    # Heatmap pour les chats
    sns.heatmap(corr_cat, annot=True, cmap='coolwarm', vmin=-1, vmax=1, ax=axes[0])
    axes[0].set_title('Matrice de corrélation - Chats')

    # Heatmap pour les chiens
    sns.heatmap(corr_dog, annot=True, cmap='coolwarm', vmin=-1, vmax=1, ax=axes[1])
    axes[1].set_title('Matrice de corrélation - Chiens')

    plt.tight_layout()
    plt.savefig(f"{output_dir}/correlation_matrices.png")
    plt.show()

def perform_pca_analysis(df, output_dir='.'):
    """Effectue une analyse en composantes principales pour visualiser la séparation des classes"""
    features = ['area', 'perimeter', 'aspect_ratio', 'circularity',
                'mean_intensity', 'std_intensity', 'energy', 'homogeneity', 'entropy']

    # Extraire les caractéristiques et les classes
    X = df[features].values
    y = (df['class'] == 'dog').astype(int)  # 0 pour chat, 1 pour chien

    # Normaliser les données
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Appliquer PCA
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)

    # Créer un DataFrame pour faciliter la visualisation
    pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])
    pca_df['class'] = df['class'].values

    # Visualiser les résultats
    plt.figure(figsize=(12, 8))
    sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='class', palette={'cat': 'blue', 'dog': 'red'},
                   alpha=0.7, s=80)

    # Ajouter des ellipses de confiance (optionnel)
    from matplotlib.patches import Ellipse

    def confidence_ellipse(x, y, ax, n_std=2.0, **kwargs):
        """
        Dessine une ellipse de confiance basée sur la covariance des données
        """
        cov = np.cov(x, y)
        pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])

        # Eigen values and eigen vectors
        eigen_values, eigen_vectors = np.linalg.eigh(cov)

        # Sort eigen vectors
        indices = np.argsort(eigen_values)[::-1]
        eigen_values = eigen_values[indices]
        eigen_vectors = eigen_vectors[:, indices]

        # Angle of largest eigenvector with x-axis
        angle = np.degrees(np.arctan2(*eigen_vectors[:, 0][::-1]))

        # Width and height
        width, height = 2 * n_std * np.sqrt(eigen_values)

        # Create the ellipse
        ellipse = Ellipse(xy=(np.mean(x), np.mean(y)),
                         width=width, height=height,
                         angle=angle, **kwargs)
        return ax.add_patch(ellipse)

    # Ajouter des ellipses pour chaque classe
    cat_data = pca_df[pca_df['class'] == 'cat']
    dog_data = pca_df[pca_df['class'] == 'dog']

    confidence_ellipse(cat_data['PC1'], cat_data['PC2'], plt.gca(), n_std=2.0,
                      alpha=0.2, facecolor='blue', edgecolor='blue', label='_nolegend_')
    confidence_ellipse(dog_data['PC1'], dog_data['PC2'], plt.gca(), n_std=2.0,
                      alpha=0.2, facecolor='red', edgecolor='red', label='_nolegend_')

    # Ajouter les vecteurs propres principaux
    for i, (component, explained) in enumerate(zip(pca.components_, pca.explained_variance_ratio_)):
        plt.arrow(0, 0, component[0]*3, component[1]*3,
                 head_width=0.2, head_length=0.2,
                 fc='green', ec='green')
        plt.text(component[0]*3.5, component[1]*3.5,
                f"PC{i+1}\n({explained:.1%})", color='green')

    plt.grid(True, linestyle='--', alpha=0.7)
    plt.title('Analyse en Composantes Principales (PCA) des caractéristiques')
    plt.xlabel(f'Composante Principale 1 ({pca.explained_variance_ratio_[0]:.2%} de variance)')
    plt.ylabel(f'Composante Principale 2 ({pca.explained_variance_ratio_[1]:.2%} de variance)')
    plt.savefig(f"{output_dir}/pca_analysis.png")
    plt.show()

    # Afficher la contribution de chaque feature aux composantes principales
    plt.figure(figsize=(12, 6))
    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)

    loadings_df = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=features)

    # Heatmap des contributions
    sns.heatmap(loadings_df, annot=True, cmap='coolwarm', center=0)
    plt.title('Contribution des caractéristiques aux composantes principales')
    plt.savefig(f"{output_dir}/pca_feature_contributions.png")
    plt.show()

def main():
    # Chemins des fichiers
    train_csv = 'train_features.csv'

    # Répertoire de sortie pour les visualisations
    output_dir = '.'

    # Charger les données
    print("Chargement des données...")
    df_train = load_data(train_csv)

    print(f"Données chargées : {df_train.shape} entrées")
    print(df_train['class'].value_counts())

    # Visualiser la distribution des caractéristiques
    print("\nVisualisation des distributions...")
    visualize_feature_distributions(df_train, output_dir)

    # Générer les matrices de corrélation
    print("\nGénération des matrices de corrélation...")
    generate_correlation_matrix(df_train, output_dir)

    # Analyse PCA
    print("\nRéalisation de l'analyse en composantes principales...")
    perform_pca_analysis(df_train, output_dir)

    print("\nAnalyse des caractéristiques terminée!")

if __name__ == "__main__":
    main()